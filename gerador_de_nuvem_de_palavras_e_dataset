import pandas as pd
import matplotlib.pyplot as plt
from wordcloud import WordCloud
import spacy
import re
import os
from collections import Counter
from unidecode import unidecode
from pandas.plotting import table
import nltk
from nltk.corpus import stopwords

# === 1. CONFIGURA칂칏ES E PASTAS ===
ARQUIVO_EXCEL = "post_saudeReddit_COMPLETO.xlsx"
ABAS = ['positivo', 'negativo', 'neutro']
ARQUIVO_EXTRAS = "conectivos_extras_final.csv"

palavras_treino = ['amo', 'feliz', 'adoro', 'raiva', 'triste', 'ansioso', 'terapia', 'sentimento', 'apoio']
palavras_cego = ['alegre', '칩dio', 'autoestima']

# Palavras que devem ser mantidas para o treino de ML
manter_no_treino = {'mais', 'menos', 'muito', 't칚o', 'tao', 'pouco'}

CORES_POLARIDADE = {'positivo': 'seagreen', 'negativo': 'indianred', 'neutro': 'mediumpurple'}
MAPAS_NUVEM = {'positivo', 'negativo', 'neutro'} # Corrigido para dicion치rio se necess치rio ou usado como set
MAPAS_NUVEM = {'positivo': 'viridis', 'negativo': 'plasma', 'neutro': 'magma'}

for folder in ['Resultados_Artigo', 'Dataset_Final_ML']:
    if not os.path.exists(folder): os.makedirs(folder)

nlp = spacy.load("pt_core_news_lg")

# === 2. STOPWORDS E LIMPEZA ===
nltk.download('stopwords')
stop_words_base = set(stopwords.words('portuguese')).union(nlp.Defaults.stop_words)

lista_extras_raw = pd.read_csv(ARQUIVO_EXTRAS)['palavra'].astype(str).tolist()
lista_extras = set([unidecode(p).lower().strip() for p in lista_extras_raw])

blindagem_ia = set(palavras_treino + palavras_cego + ["n칚o", "nao", "nem", "nunca", "jamais", "sem"])
stop_words_treino = (stop_words_base.union(lista_extras)) - blindagem_ia - manter_no_treino
stop_words_nuvem = stop_words_base.union(lista_extras).union({'nao', 'n칚o'})

# === 3. FUN칂칏ES DE APOIO ===
def gerar_tabela_cientifica(df_base, nome_arquivo, titulo, tipo='abs'):
    ct = pd.crosstab([df_base['polaridade'], df_base['palavraChave']], df_base['subreddit'], margins=True)
    if tipo == 'perc':
        ct = ct.div(ct['All'], axis=0) * 100
        df_plot = ct.round(1).astype(str) + '%'
    else:
        df_plot = ct.astype(str)

    fig, ax = plt.subplots(figsize=(12, len(df_plot)*0.5 + 2))
    ax.axis('off')
    tbl = table(ax, df_plot, loc='center', cellLoc='center')
    tbl.auto_set_font_size(False); tbl.set_fontsize(9); tbl.scale(1.2, 1.5)
    plt.title(titulo, fontsize=12, weight='bold', pad=10)
    plt.savefig(f"Resultados_Artigo/{nome_arquivo}.png", dpi=300, bbox_inches='tight')
    plt.close()
    
    # Log no terminal
    print(f"\n游늵 {titulo}")
    print(df_plot)

def limpar_ia(texto):
    t_fase1 = re.sub(r'[.,!?();:/]', ' ', unidecode(str(texto)).lower())
    palavras_texto = t_fase1.split()
    texto_filtrado = " ".join([p for p in palavras_texto if p not in lista_extras])
    doc = nlp(texto_filtrado)
    finais = []
    for t in doc:
        lema = t.lemma_.lower().strip()
        if re.fullmatch(r'k+', lema) and len(lema) > 1:
            continue
        if t.pos_ in ["NOUN", "ADJ", "VERB", "ADV"] and len(lema) > 2:
            if lema not in stop_words_treino and lema not in lista_extras:
                finais.append(lema)
    return " ".join(finais)

def limpar_visual(texto):
    t_fase1 = re.sub(r'[.,!?();:/]', ' ', unidecode(str(texto)).lower())
    palavras_texto = t_fase1.split()
    texto_filtrado = " ".join([p for p in palavras_texto if p not in lista_extras])
    doc = nlp(texto_filtrado)
    finais = []
    for t in doc:
        lema = t.lemma_.lower().strip()
        if t.pos_ in ["NOUN", "ADJ"] and lema not in stop_words_nuvem and len(lema) > 2:
            finais.append(lema)
    return " ".join(finais)

# === 4. PROCESSAMENTO ===
print(" Iniciando Processamento...")

# Dataset completo
df_total = pd.concat([pd.read_excel(ARQUIVO_EXCEL, sheet_name=a).assign(polaridade=a) for a in ABAS]).dropna(subset=['texto', 'palavraChave'])

# REMO칂츾O DA COLUNA USU츼RIO (Anonimiza칞칚o)
# Remove a coluna 'autor' (ou 'usuario') se ela existir
df_total = df_total.drop(columns=['autor', 'usuario'], errors='ignore')

# === TABELAS DATASET BRUTO ===
gerar_tabela_cientifica(df_total, "img_tabela_1_BRUTA_abs", "Tabela 1: Dataset Bruto Completo (Absoluto)")
gerar_tabela_cientifica(df_total, "img_tabela_2_BRUTA_perc", "Tabela 2: Dataset Bruto Completo (%)", tipo='perc')

# --- BLOCO TREINO BALANCEADO ---
posts_treino_bal = []
for kw in palavras_treino:
    df_kw = df_total[df_total['palavraChave'] == kw]
    amostra = df_kw.sample(n=min(len(df_kw), 500), random_state=42).copy()
    amostra['texto_treino_ml'] = amostra['texto'].apply(limpar_ia)
    posts_treino_bal.append(amostra)
    
    # WordCloud e gr치fico de barras
    txt_v = " ".join([limpar_visual(t) for t in amostra['texto']])
    if txt_v:
        contagem = Counter(txt_v.split()).most_common(20)
        pol = amostra['polaridade'].iloc[0]
        WordCloud(width=800, height=400, background_color='white', colormap=MAPAS_NUVEM[pol]).generate(txt_v).to_file(f"Resultados_Artigo/nuvem_{kw}.png")
        df_f = pd.DataFrame(contagem, columns=["Palavra", "Freq"])
        plt.figure(figsize=(10,6))
        plt.bar(df_f["Palavra"], df_f["Freq"], color=CORES_POLARIDADE[pol])
        plt.xticks(rotation=45, ha='right')
        plt.tight_layout()
        plt.savefig(f"Resultados_Artigo/predios_{kw}.png", dpi=300)
        plt.close()
        print(f"\n TOP 20 palavras (Visual) para {kw.upper()}:")
        for palavra, freq in contagem:
            print(f"{palavra:<15} | {freq}")

df_treino_final = pd.concat(posts_treino_bal)

# --- BLOCO CEGO BALANCEADO ---
posts_cego_bal = []
for kw in palavras_cego:
    df_kw = df_total[df_total['palavraChave'] == kw]
    amostra = df_kw.sample(n=min(len(df_kw), 200), random_state=7).copy()
    amostra['texto_treino_ml'] = amostra['texto'].apply(limpar_ia)
    posts_cego_bal.append(amostra)
df_cego_final = pd.concat(posts_cego_bal)

# === TABELAS TREINO E CEGO ===
gerar_tabela_cientifica(df_treino_final, "img_tabela_3_TREINO_abs", "Tabela 3: Dataset Treino Balanceado (Absoluto)")
gerar_tabela_cientifica(df_treino_final, "img_tabela_4_TREINO_perc", "Tabela 4: Dataset Treino Balanceado (%)", tipo='perc')
gerar_tabela_cientifica(df_cego_final, "img_tabela_5_CEGO_abs", "Tabela 5: Dataset Teste Cego (Absoluto)")
gerar_tabela_cientifica(df_cego_final, "img_tabela_6_CEGO_perc", "Tabela 6: Dataset Teste Cego (%)", tipo='perc')

# === SALVAR CSV ===
df_treino_final.to_csv('Dataset_Final_ML/TREINO_BALANCEADO.csv', index=False)
df_cego_final.to_csv('Dataset_Final_ML/TESTE_CEGO.csv', index=False)

print("\n PROCESSO FINALIZADO! Todas as 6 tabelas geradas e log de palavras no terminal.")